{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Neural Network Regression in TensorFlow**\n",
        "\n",
        "üëÅÔ∏èüëÅÔ∏è Looking to solve Regression Problems\n",
        "\n",
        " - Architecture of a neural network regression model\n",
        " - Input shapes and output shapes of a regression model (**features** and labels)\n",
        " - Creating custom data to view and fit\n",
        " - Steps in modelling\n",
        "  - Creating a model, compiling a model, fitting a model, evaluating a model.\n",
        " - Different evaluation methods\n",
        " - Saving and loading models"
      ],
      "metadata": {
        "id": "f5wjJGSx6-YW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNH8xU5Y6G44",
        "outputId": "794bd7d5-895b-4840-eae9-368c760b93c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ],
      "source": [
        "# Import Tensorflow\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating data to view and fit"
      ],
      "metadata": {
        "id": "e0iBPtjeCCqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create features\n",
        "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
        "\n",
        "# Create labels\n",
        "y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
        "\n",
        "# Visualize it\n",
        "plt.scatter(X, y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "XZ5Rvn-1Ecxe",
        "outputId": "5c9385e9-dbb3-403e-c84f-036fe450dc44"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7af8810f6770>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is how we get y values from this values (the linear regression of this very simple model)\n",
        "X + 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67oKXtvcFM7V",
        "outputId": "25320f0e-f6c0-400b-bb98-b8c39e14c4d8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y == X + 10\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2bcTt9MFlC0",
        "outputId": "469bb359-e6d5-4c5d-84bf-51f08c46a2a4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Input and Output Shapes"
      ],
      "metadata": {
        "id": "yPxHTWJdFnrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a demo tenosr for our housing price prediction problem\n",
        "house_info = tf.constant(['bedroom','bathroom','garage'])\n",
        "house_price = tf.constant([939700])\n",
        "house_info, house_price"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlQOdSPNGRiP",
        "outputId": "5dabd8b2-304c-42e4-ef7c-cc064166f9ef"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
              " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0], y[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpdDsnPZIsmn",
        "outputId": "cf5b2005-fb84-4adc-eded-b2ad45effbd9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-7.0, 3.0)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape\n",
        "input_shape, output_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZy0Zyt3G3Pj",
        "outputId": "da23ce0c-5162-4c2b-fdec-2b34f62396fe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((), ())"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn our NumPy arrays into tensors\n",
        "X = tf.cast(tf.constant(X), dtype=tf.float32)\n",
        "y = tf.cast(tf.constant(y), dtype=tf.float32)\n",
        "\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpH980DyHIxj",
        "outputId": "096c15eb-b16c-4014-d594-4435ddd88784"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape\n",
        "input_shape, output_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bVYtQdFLiMH",
        "outputId": "2d498f44-ce10-4a9e-cdea-5d3ac61ff728"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([]), TensorShape([]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X, y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "49bMIexxLno-",
        "outputId": "76c1d037-0e6d-4b28-81a7-34044a07b524"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7af87f03d720>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Steps in modelling with TensorFlow\n",
        "\n",
        "1. **Creating a model** - define the input and output layers, as well as the hidden layers of a deep learning model.\n",
        "2. **Compiling a model** - define the loss function (in other words, the function which tells our model how worng it is), the optimizer (tells our model how to improve the patterns its learning), and the evaluation metrics (what we can use to interpret the performance of our model).\n",
        "3. **Fitting a model** - letting the model try to find patterns between X & y (features & labels). Epochs - How many times the model will go through all of the training examples\n",
        "4. **Evaluate the model** on the test data (how reliable are our models predictions?)\n"
      ],
      "metadata": {
        "id": "wMt8oXAML0kn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create amodel using the sequential API\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "]) # into a list method\n",
        "\n",
        "# add method\n",
        "# model = tf.keras.Sequential()\n",
        "# model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae, #mae is short for mean absolute error\n",
        "              optimizer=tf.keras.optimizers.SGD(), #SGD is short for Stochastic Gradient Descent\n",
        "              metrics=['mae'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlQ3HrGyL9ve",
        "outputId": "931d523e-e59e-4bb4-de9e-5a8c4abd3a43"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 9.9084 - mae: 9.9084\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 9.7759 - mae: 9.7759\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 9.6434 - mae: 9.6434\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 9.5109 - mae: 9.5109\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.3784 - mae: 9.3784\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7af87c5c27d0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out X and y\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYSR2YinqtYI",
        "outputId": "4d138f9e-4d5b-41df-a196-c4d2255aead0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try and make a prediction using our model\n",
        "model.predict([17.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh4K2jbqucOa",
        "outputId": "46b6b46a-58a9-437b-d119-3822c3d64167"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 165ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[20.47005]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Improving our model\n",
        "\n",
        "We can improve our model, by altering the steps we took to create a model.\n",
        "\n",
        "1. **Creating a model** - here we might add more layers, increase the number of hidden units (all called neurons) within each of the hidden layers, change the activation function of each layer.\n",
        "2. **Compiling a model** - here we might change the optimization fucntion or perhaps the **learning rate** of the optimization function.\n",
        "3. **Fitting a model** - here we might fit the model for more **epochs** (leave it training for longer) or on more data (give the model more examples to learn from)."
      ],
      "metadata": {
        "id": "uhwABg2_ulcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rebuilding our model\n",
        "\n",
        "# 1. Creating the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compiling the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=['mae'])\n",
        "\n",
        "# 3. Fit the model (this time we'll train for longer)\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKveIxuqUtMq",
        "outputId": "9833a148-e454-4f74-b622-684e4756858e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 17.8537 - mae: 17.8537\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 17.5725 - mae: 17.5725\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 17.2912 - mae: 17.2912\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 17.0100 - mae: 17.0100\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 16.7287 - mae: 16.7287\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 16.4475 - mae: 16.4475\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 16.1662 - mae: 16.1662\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 15.8850 - mae: 15.8850\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 15.6037 - mae: 15.6037\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 15.3225 - mae: 15.3225\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 15.0412 - mae: 15.0412\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 14.7987 - mae: 14.7987\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 14.6662 - mae: 14.6662\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 14.5337 - mae: 14.5337\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 14.4012 - mae: 14.4012\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 14.2687 - mae: 14.2687\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 14.1362 - mae: 14.1362\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 14.0037 - mae: 14.0037\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 13.8712 - mae: 13.8712\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 13.7387 - mae: 13.7387\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 13.6062 - mae: 13.6062\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 13.4737 - mae: 13.4737\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 13.3412 - mae: 13.3412\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 13.2087 - mae: 13.2087\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 13.0762 - mae: 13.0762\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 12.9437 - mae: 12.9437\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 12.8112 - mae: 12.8112\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 12.6787 - mae: 12.6787\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 12.5462 - mae: 12.5462\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 12.4137 - mae: 12.4137\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 12.2812 - mae: 12.2812\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 12.1487 - mae: 12.1487\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 12.0162 - mae: 12.0162\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 11.8837 - mae: 11.8837\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 11.7512 - mae: 11.7512\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 11.6187 - mae: 11.6187\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 11.4862 - mae: 11.4862\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 11.3537 - mae: 11.3537\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 11.2212 - mae: 11.2212\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 11.0887 - mae: 11.0887\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 10.9562 - mae: 10.9562\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 10.8237 - mae: 10.8237\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 10.6912 - mae: 10.6912\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 10.5587 - mae: 10.5587\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 10.4262 - mae: 10.4262\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 10.2937 - mae: 10.2937\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 10.1612 - mae: 10.1612\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 10.0287 - mae: 10.0287\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 9.8962 - mae: 9.8962\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 9.7637 - mae: 9.7637\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 9.6312 - mae: 9.6312\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 9.4987 - mae: 9.4987\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 9.3662 - mae: 9.3662\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 9.2337 - mae: 9.2337\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 9.1012 - mae: 9.1012\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 8.9687 - mae: 8.9687\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 8.8362 - mae: 8.8362\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 8.7037 - mae: 8.7037\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 8.5712 - mae: 8.5712\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 8.4387 - mae: 8.4387\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 8.3062 - mae: 8.3062\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 8.1737 - mae: 8.1737\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 8.0412 - mae: 8.0412\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 7.9087 - mae: 7.9087\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.7762 - mae: 7.7762\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.6437 - mae: 7.6437\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7.5112 - mae: 7.5112\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 7.3787 - mae: 7.3787\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 7.2462 - mae: 7.2462\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.1137 - mae: 7.1137\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6.9956 - mae: 6.9956\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6.9900 - mae: 6.9900\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 6.9844 - mae: 6.9844\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.9788 - mae: 6.9788\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 6.9731 - mae: 6.9731\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 6.9675 - mae: 6.9675\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.9619 - mae: 6.9619\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.9563 - mae: 6.9563\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.9506 - mae: 6.9506\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 6.9450 - mae: 6.9450\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9394 - mae: 6.9394\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.9338 - mae: 6.9338\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.9281 - mae: 6.9281\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 6.9225 - mae: 6.9225\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.9169 - mae: 6.9169\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 6.9113 - mae: 6.9113\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 6.9056 - mae: 6.9056\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.9000 - mae: 6.9000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 6.8944 - mae: 6.8944\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.8888 - mae: 6.8888\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.8831 - mae: 6.8831\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 6.8775 - mae: 6.8775\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.8719 - mae: 6.8719\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 6.8663 - mae: 6.8663\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.8606 - mae: 6.8606\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 6.8550 - mae: 6.8550\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.8494 - mae: 6.8494\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.8438 - mae: 6.8438\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.8381 - mae: 6.8381\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.8325 - mae: 6.8325\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7af87c409930>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remind the data\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScmQsLJQXrFI",
        "outputId": "6166c7f3-d848-4791-c18b-824c98aea196"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see if the model prediction has improved\n",
        "model.predict([17.])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvbtrPKkYbkP",
        "outputId": "44d3ffff-1b16-468f-b3ce-41f3216d55e4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 353ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.293575]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rebuilding (third time) our model\n",
        "# Adding a hidden layer\n",
        "\n",
        "# 1. Creating the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compiling the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=['mae'])\n",
        "\n",
        "# 3. Fit the model (this time we'll train for longer)\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vb5bklpEYqTO",
        "outputId": "14926a2e-1361-4416-e48e-ca8a09535b24"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 646ms/step - loss: 12.9911 - mae: 12.9911\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 12.2326 - mae: 12.2326\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.5363 - mae: 11.5363\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 10.7901 - mae: 10.7901\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 9.9304 - mae: 9.9304\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 8.8728 - mae: 8.8728\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.5279 - mae: 7.5279\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.7260 - mae: 5.7260\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.9018 - mae: 3.9018\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.1225 - mae: 4.1225\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.9004 - mae: 3.9004\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 4.0749 - mae: 4.0749\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.9124 - mae: 3.9124\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 4.0265 - mae: 4.0265\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.9268 - mae: 3.9268\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.9805 - mae: 3.9805\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.9733 - mae: 3.9733\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.9030 - mae: 3.9030\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.9935 - mae: 3.9935\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.8470 - mae: 3.8470\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.0120 - mae: 4.0120\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.7979 - mae: 3.7979\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.0092 - mae: 4.0092\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.8146 - mae: 3.8146\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.9491 - mae: 3.9491\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.8698 - mae: 3.8698\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.8725 - mae: 3.8725\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.8903 - mae: 3.8903\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.8123 - mae: 3.8123\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.9122 - mae: 3.9122\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.7507 - mae: 3.7507\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.9343 - mae: 3.9343\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.7252 - mae: 3.7252\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.9059 - mae: 3.9059\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.7484 - mae: 3.7484\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.8433 - mae: 3.8433\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.7722 - mae: 3.7722\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.7883 - mae: 3.7883\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.8268 - mae: 3.8268\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.6950 - mae: 3.6950\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.8527 - mae: 3.8527\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.6495 - mae: 3.6495\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.8432 - mae: 3.8432\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.6754 - mae: 3.6754\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.7756 - mae: 3.7756\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.7020 - mae: 3.7020\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.7059 - mae: 3.7059\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.7303 - mae: 3.7303\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.6368 - mae: 3.6368\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.7897 - mae: 3.7897\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.5898 - mae: 3.5898\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.7591 - mae: 3.7591\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.6179 - mae: 3.6179\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.6864 - mae: 3.6864\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.6475 - mae: 3.6475\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.6111 - mae: 3.6111\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.6789 - mae: 3.6789\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.5333 - mae: 3.5333\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.7119 - mae: 3.7119\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.5164 - mae: 3.5164\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.6840 - mae: 3.6840\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.5761 - mae: 3.5761\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.5733 - mae: 3.5733\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.6092 - mae: 3.6092\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.4914 - mae: 3.4914\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.6442 - mae: 3.6442\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.4523 - mae: 3.4523\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.6225 - mae: 3.6225\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.4906 - mae: 3.4906\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.5332 - mae: 3.5332\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.5256 - mae: 3.5256\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.4471 - mae: 3.4471\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.5630 - mae: 3.5630\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.3776 - mae: 3.3776\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.5510 - mae: 3.5510\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.4403 - mae: 3.4403\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.4615 - mae: 3.4615\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.4771 - mae: 3.4771\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.3698 - mae: 3.3698\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.5155 - mae: 3.5155\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.3299 - mae: 3.3299\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.4863 - mae: 3.4863\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.3668 - mae: 3.3668\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.3919 - mae: 3.3919\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.4056 - mae: 3.4056\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.2932 - mae: 3.2932\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.4449 - mae: 3.4449\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.2678 - mae: 3.2678\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.3866 - mae: 3.3866\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.3292 - mae: 3.3292\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.2827 - mae: 3.2827\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.3681 - mae: 3.3681\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.1894 - mae: 3.1894\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.3853 - mae: 3.3853\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.2296 - mae: 3.2296\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.2756 - mae: 3.2756\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.2701 - mae: 3.2701\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.1667 - mae: 3.1667\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.3137 - mae: 3.3137\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.1397 - mae: 3.1397\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7af86cf2d0c0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict([17.])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrBO9geZZkDd",
        "outputId": "014858dc-6039-4387-817f-378a663a8d03"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 43ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.56271]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rebuilding our model\n",
        "\n",
        "# 1. Creating the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(50, activation=None),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compiling the model\n",
        "model.compile(loss='mae',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "              metrics=['mae'])\n",
        "\n",
        "# 3. Fit the model (this time we'll train for longer)\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UKofvlaZq4t",
        "outputId": "2b54e9fb-9809-4f4f-cd27-e72cd17fa6ee"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 629ms/step - loss: 13.1127 - mae: 13.1127\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 12.4096 - mae: 12.4096\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 11.7070 - mae: 11.7070\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.0032 - mae: 11.0032\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 10.2960 - mae: 10.2960\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.5823 - mae: 9.5823\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.8590 - mae: 8.8590\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.1228 - mae: 8.1228\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.3706 - mae: 7.3706\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.7955 - mae: 6.7955\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.8743 - mae: 6.8743\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1517 - mae: 7.1517\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.3147 - mae: 7.3147\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.4640 - mae: 7.4640\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.4143 - mae: 7.4143\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1981 - mae: 7.1981\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9447 - mae: 6.9447\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.6993 - mae: 6.6993\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.4351 - mae: 6.4351\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.1567 - mae: 6.1567\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.0912 - mae: 6.0912\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.0477 - mae: 6.0477\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.1476 - mae: 6.1476\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.1414 - mae: 6.1414\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.0431 - mae: 6.0431\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.8630 - mae: 5.8630\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.6455 - mae: 5.6455\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.5438 - mae: 5.5438\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.4388 - mae: 5.4388\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.3303 - mae: 5.3303\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.3353 - mae: 5.3353\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.2961 - mae: 5.2961\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.2134 - mae: 5.2134\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.0908 - mae: 5.0908\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.9313 - mae: 4.9313\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.7381 - mae: 4.7381\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.6176 - mae: 4.6176\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.5160 - mae: 4.5160\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 4.4064 - mae: 4.4064\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 4.3878 - mae: 4.3878\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 4.2544 - mae: 4.2544\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 4.0073 - mae: 4.0073\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.8321 - mae: 3.8321\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.6793 - mae: 3.6793\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.6023 - mae: 3.6023\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.4700 - mae: 3.4700\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.2850 - mae: 3.2850\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0499 - mae: 3.0499\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.8144 - mae: 2.8144\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.6363 - mae: 2.6363\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.5126 - mae: 2.5126\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.2848 - mae: 2.2848\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.9984 - mae: 1.9984\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.8087 - mae: 1.8087\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6202 - mae: 1.6202\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.3621 - mae: 1.3621\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0373 - mae: 1.0373\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8703 - mae: 0.8703\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6387 - mae: 0.6387\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2307 - mae: 0.2307\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4153 - mae: 0.4153\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5902 - mae: 0.5902\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6056 - mae: 0.6056\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.8523 - mae: 0.8523\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.0427 - mae: 1.0427\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.9821 - mae: 0.9821\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.8368 - mae: 0.8368\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.9822 - mae: 0.9822\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.9494 - mae: 0.9494\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7314 - mae: 0.7314\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6073 - mae: 0.6073\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5703 - mae: 0.5703\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.3439 - mae: 0.3439\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1755 - mae: 0.1755\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2941 - mae: 0.2941\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2401 - mae: 0.2401\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4641 - mae: 0.4641\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5540 - mae: 0.5540\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4816 - mae: 0.4816\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4161 - mae: 0.4161\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4368 - mae: 0.4368\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2968 - mae: 0.2968\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2844 - mae: 0.2844\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1965 - mae: 0.1965\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0367 - mae: 0.0367\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1163 - mae: 0.1163\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1820 - mae: 0.1820\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1878 - mae: 0.1878\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1515 - mae: 0.1515\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1383 - mae: 0.1383\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0427 - mae: 0.0427\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1030 - mae: 0.1030\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1256 - mae: 0.1256\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1725 - mae: 0.1725\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1323 - mae: 0.1323\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0911 - mae: 0.0911\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0314 - mae: 0.0314\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1205 - mae: 0.1205\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1629 - mae: 0.1629\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1642 - mae: 0.1642\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7af867c6c910>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict([25.])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymwdU8OhcNhr",
        "outputId": "3d80a3ee-0f34-4e6f-8b84-ca39abfcc835"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7af867960280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 135ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[34.18231]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### RECAP: Common ways to improve a deep model\n",
        "- Adding layers\n",
        "- Increase the number of hideen units\n",
        "- Change the activation functions\n",
        "- Change the optimization function\n",
        "- Change the learning rate (üëÅÔ∏è The most useful hyperparameter to improve our neural network)\n",
        "- Sampling more data (bigger datasets)\n",
        "- Fitting training for longer (epochs)"
      ],
      "metadata": {
        "id": "xFgDf9-feGtW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating a model"
      ],
      "metadata": {
        "id": "X1HRwypid5_q"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JRfP-VnlfOmx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}